# ScrabePicker

Great! Below is a **set of AI prompts** you can use to develop or fine-tune each step in your image processing pipeline using tools like **OpenCV**, **TinyML**, or even custom-trained models with **Edge Impulse**, **Roboflow**, or **YOLOv5**.

These prompts are structured so you can copy and use them in your AI tools or assistants (like me, or other AI modeling platforms) to generate or guide implementation code and models.

---

## ğŸ”§ AI Prompts for Each Step in the Vision Pipeline

---

### ğŸ¥ 1. **Frame Capture (PiCam)**
> **Prompt**:  
â€œWrite Python code to continuously capture frames using Raspberry Pi Camera V2 and display them using OpenCV.â€

---

### ğŸ§¼ 2. **Image Preprocessing**
> **Prompt**:  
â€œGenerate OpenCV code that takes a captured BGR image, resizes it to 640x480, applies Gaussian blur (kernel 5x5), converts it to grayscale, and returns the preprocessed image.â€

---

### ğŸªµ 3. **Floor Segmentation (Texture or Color Based)**
> **Prompt (Color-based)**:  
â€œWrite OpenCV code to extract the floor region from an image using HSV color thresholding. The floor is a uniform light brown.â€

> **Prompt (Texture-based)**:  
â€œCreate a Python function to segment the floor area using texture analysis with Gabor filters or LBP features in OpenCV.â€

---

### ğŸ”² 4. **Perspective Correction**
> **Prompt**:  
â€œGenerate code to apply a top-down perspective transform (homography) to a floor view. Assume you have 4 manually selected points from the image and their mapped top-down positions.â€

---

### ğŸŸ  5. **Small Object Detection (Contours + Filtering)**
> **Prompt**:  
â€œCreate OpenCV code to detect objects on the floor using adaptive thresholding and contour detection. Filter objects by size: detect only contours with area between 100 and 1500 pixels.â€

---

### ğŸ§± 6. **Obstacle Detection (Larger Object Filtering)**
> **Prompt**:  
â€œUsing the same contour method, classify large contours (area > 3000) as obstacles and draw bounding boxes in red on them.â€

---

### ğŸ§­ 7. **Real-World Position Mapping**
> **Prompt**:  
â€œGenerate Python code to convert (x, y) pixel coordinates from a warped top-down image into real-world coordinates using known camera parameters and a precomputed homography matrix.â€

---

### ğŸ§  8. **Object Classification (Optional, Advanced)**
> **Prompt (Traditional)**:  
â€œWrite a Python function to classify detected objects on the floor based on shape (circular, rectangular) using contour moments and Hu moments.â€

> **Prompt (TinyML)**:  
â€œTrain a lightweight object detection model to detect small pickable trash items (paper balls, wrappers) using Roboflow or Edge Impulse. Export for Raspberry Pi inference.â€

---

### ğŸ¤– 9. **Action Triggering Logic**
> **Prompt**:  
â€œWrite a Python function that receives detected object coordinates and types (small_object or obstacle), and decides whether to send â€˜MOVE_TOâ€™, â€˜PICK_OBJECTâ€™, â€˜AVOID_OBSTACLEâ€™ or â€˜DROP_OBJECTâ€™ commands over UART.â€

---

### ğŸ”Œ 10. **Raspberry Pi â†” Arduino Communication**
> **Prompt**:  
â€œWrite Python code using `pyserial` to send simple command strings from Raspberry Pi to Arduino over serial (e.g., 'MOVE_TO:10,20', 'PICK_OBJECT'). Include basic error handling.â€

---

### âš™ï¸ 11. **Arduino Command Parser**
> **Prompt**:  
â€œWrite Arduino C++ code that listens to incoming serial messages like â€˜MOVE_TO:x,yâ€™, â€˜PICK_OBJECTâ€™, and parses them to control 4 DC motors and a servo gripper.â€

---

### ğŸ§  Bonus: **End-to-End Flow**
> **Prompt**:  
â€œDesign an end-to-end image processing pipeline using Raspberry Pi, OpenCV, and Arduino to detect small objects on the floor, avoid large ones, and pick/drop objects using serial communication.â€

---

Let me know which step you want implemented first, and I can generate code and logic for that immediately!
